# Learning to Generate Diverse Pedestrian Movements from Web Videos with Noisy Labels

<a href="https://arxiv.org/abs/2410.07500"><img src="https://img.shields.io/badge/arXiv-Paper-red"></a> 
<a href="https://genforce.github.io/PedGen"><img src="https://img.shields.io/badge/Project-Page-yellow"></a>
[![GitHub](https://img.shields.io/github/stars/genforce/PedGen?style=social)](https://github.com/genforce/PedGen)

[Zhizheng Liu](https://scholar.google.com/citations?user=Asc7j9oAAAAJ&hl=en), [Joe Lin](https://github.com/joe-lin-tech), [Wayne Wu](https://wywu.github.io/), [Bolei Zhou](https://boleizhou.github.io/)
 <br>
     University of California, Los Angeles
 <br>
 ![Teaser](/docs/assets/teaser.jpg)

 ## Getting Started

 We plan to release our dataset and code by the end of November 2024, please stay tuned!


 ## Contact

For any questions or discussions, please contact [Zhizheng Liu](https://scholar.google.com/citations?user=Asc7j9oAAAAJ&hl=en) (zhizheng@cs.ucla.edu).

## Reference

If our work is helpful to your research, please cite the following:

```bibtex
@article{liu2024learning,
    title={Learning to Generate Diverse Pedestrian Movements from Web Videos with Noisy Labels},
    author={Liu, Zhizheng and Lin, Joe and Wu, Wayne and Zhou, Bolei},
    journal={arXiv preprint arXiv:2410.07500},
    year={2024}
}
```